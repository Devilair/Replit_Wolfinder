Wolfinder è una piattaforma full-stack basata su Next.js 14 e MongoDB, sviluppata da un singolo programmatore non esperto. L’obiettivo è completare il progetto in modo più rapido e semplice possibile sfruttando assistenti IA come Claude AI (che supporta contesti fino a 200.000 token), ChatGPT e strumenti di sviluppo integrati con l’IA. In questa guida analizziamo una strategia concreta ed efficiente che combina questi strumenti per:
Ridurre drasticamente i tempi e la complessità di programmazione, evitando ripetizioni inutili.
Mantenere la continuità del contesto del progetto anche superando i limiti di memoria delle chat.
Gestire agevolmente più file e una struttura complessa (cartelle Next.js, API routes, componenti, modelli Mongoose, ecc.).
Integrare Claude, ChatGPT e altri strumenti (VS Code, GitHub Copilot, plugin, editor AI come Cursor, ecc.) in sinergia nel flusso di lavoro quotidiano.
Suggerire strumenti, plugin, automazioni e workflow usati da sviluppatori reali e tecniche di gestione del contesto (LangChain, RAG, indicizzazione file, segmentazione del codice, ecc.) accessibili anche a un utente non esperto.
Seguono sezioni dettagliate con esempi pratici, liste di strumenti consigliati e best practice operative per portare a termine Wolfinder in modo efficiente con l’ausilio dell’IA.
Salvare e mantenere il contesto del progetto tra sessioni
Un problema comune usando chat AI è dover reinserire da zero il contesto del progetto ad ogni nuova sessione. Claude AI offre una funzione chiamata “Projects” proprio per mantenere il contesto nel tempo. Un Project in Claude è uno spazio di lavoro dedicato in cui puoi caricare file e documenti rilevanti e avere conversazioni che persistono nel tempo. Diversamente dalle chat normali che ripartono senza memoria, un Project conserva il contesto attraverso più conversazioni: Claude può quindi far riferimento a documenti caricati in precedenza e alle interazioni passate nel progetto
beginswithai.com
. Inoltre, i Projects permettono di creare una sorta di base di conoscenza personalizzata, poiché puoi uploadare file con specifiche, descrizioni tecniche, appunti, ecc., che Claude userà per dare risposte più pertinenti
beginswithai.com
. Come sfruttare questa caratteristica? All’inizio del progetto Wolfinder, conviene creare un Project dedicato su Claude e caricarvi materiale di contesto, ad esempio:
Descrizione del progetto e obiettivi: un documento riassuntivo di cosa fa Wolfinder, le funzionalità previste e i requisiti.
Struttura del codice e convenzioni: ad esempio un file che spiega l’architettura delle cartelle Next.js (pagine, API, componenti), le convenzioni di naming, linee guida di codice, ecc. Puoi far generare queste descrizioni stesse a Claude man mano e poi salvarle.
Modelli di dati e schema DB: ad esempio definizioni Mongoose, relazioni tra collezioni, ecc.
Logica di business o flussi principali: un documento con la descrizione di come funziona il matching in Wolfinder, regole particolari, etc.
Lista di task o roadmap: ciò che resta da implementare o bug da correggere.
Questi file caricati nel Project fungono da memoria a lungo termine e contesto di base per Claude
reddit.com
. In questo modo, quando apri una nuova chat all’interno di quel progetto, non devi incollare di nuovo tutto il contesto manualmente: Claude ricorderà le informazioni dai file caricati (p.es. descrizione del progetto, struttura, convenzioni) e anche alcune conversazioni precedenti. Puoi anche aggiungere custom instructions specifiche per il progetto (ad es. “rispondi sempre in italiano”, oppure “usa uno stile conciso”, ecc.) per personalizzare il comportamento di Claude nelle chat di quel progetto
beginswithai.com
. Evitare di sovraccaricare il contesto: Anche se Claude Projects supporta un contesto fino a 200k token (molto ampio)
beginswithai.com
, non è consigliabile caricare tutto il codice sorgente integrale come file separati nel progetto. Un approccio migliore (testato da utenti) è usare i file di progetto come “knowledge base” generale e memoria a lungo termine, anziché come deposito di ogni singolo file di codice
reddit.com
. In pratica:
Carica nei Project files documentazione e riassunti, non l’intero codice sorgente riga per riga
reddit.com
. Ad esempio, invece di caricare 20 file di codice, puoi caricare un documento con la descrizione di ciascun modulo o una panoramica delle API esposte.
Quando serve discutere del codice specifico, fornisci tu nella chat i file o gli snippet rilevanti in quel momento (puoi copiarli e incollarli, o usare strumenti per estrarli, vedi sezione successiva). In nuove conversazioni, includi solo i file necessari per la domanda attuale, evitando di saturare il contesto del progetto
reddit.com
. Questo mantiene il focus della chat e riduce il consumo di token.
Aggiorna costantemente i file di contesto nel Project: dopo una sessione di brainstorming, ad esempio, puoi chiedere a Claude di generare un documento di design o un riepilogo delle decisioni e poi salvarlo tra i file del progetto
reddit.com
. Questo diventa parte della memoria condivisa. Analogamente, se pianificate un refactoring, fatevi aiutare a stendere un piano a fasi e salvate anche quello
reddit.com
, così nelle sessioni successive potrete dire “Claude, ricordati il piano salvato, siamo alla fase 2…”.
Considera di creare un file speciale tipo PROJECT_CONTEXT.md (simile al concetto di CLAUDE.md usato da Claude Code, vedi più avanti) dove tieni un riassunto manuale del contesto e lo aggiorni quando cambiano cose importanti. Questo file può essere caricato nel Project Claude o anche copiato in ChatGPT all’occorrenza.
In breve, usa la memoria persistente di Claude per il contesto generale del progetto e le decisioni chiave, in modo da non ripeterti ogni volta, ma gestisci in maniera mirata il codice dettagliato fornendolo solo quando serve. Questo equilibrio permette continuità senza sforare i limiti di contesto.
Nota: ChatGPT (GPT-4) non ha una funzione analoga di Projects con file persistenti. Tuttavia, puoi ottenere qualcosa di simile usando un thread unico per il progetto (mantenendo la conversazione aperta), oppure sfruttando le Custom Instructions di ChatGPT (nella sezione Impostazioni) per inserire un breve contesto permanente. Tieni però conto che il contesto di ChatGPT è limitato (tipicamente 8K o 32K token se hai accesso a GPT-4 32k). Pertanto, anche con ChatGPT conviene avere a portata di mano riassunti del progetto da incollare quando inizi una nuova chat. Puoi persino chiedere a ChatGPT di riassumere il progetto Wolfinder in X parole e tenere quel riassunto pronto per future richieste.
Gestione efficiente di più file e struttura complessa
Lavorare su un progetto Next.js significa gestire molti file e cartelle: pagine front-end, componenti React, API route (serverless functions), file di configurazione, modelli Mongoose, ecc. Per un’IA, comprendere il progetto spesso richiede di vedere più file insieme, ad esempio per seguire il flusso dal front-end al back-end o per modificare codice correlato in diversi punti. 1. Fornire all’AI più file alla volta:
Claude con 200k token di contesto può teoricamente accettare decine di migliaia di righe di codice in input. In pratica però è bene inviare solo i file necessari per il task corrente. Ad esempio, se stai lavorando su un’API di login, potresti passare a Claude il file API (endpoint Next.js), il modello utente Mongoose e magari il componente di form al front-end, chiedendo di controllare la coerenza o suggerire modifiche considerando tutti e tre. Preparare manualmente questi incolli può essere noioso; ecco alcune tattiche per semplificare:
Script di concatenazione dei file: Puoi scrivere (o farti aiutare a scrivere) uno script che data una cartella o una lista di file, li unisce in un unico testo, con magari separatori chiari tra uno e l’altro (es. // File: path/nomefile.js inserito tra i file)
reddit.com
. In chat con Claude, incolli questo testo concatenato così l’AI vede tutti i file insieme. Alcuni sviluppatori usano proprio questo metodo con Claude per gestire grossi codebase, ed evitano così di caricare troppi file singoli nel Project
reddit.com
reddit.com
. Dopo che Claude ha elaborato la risposta o modificato il codice concatenato, puoi usare uno script inverso per splittare l’output e salvare ciascun file modificato al posto giusto (magari verificando il diff con Git).
Utilizzare tool di sync con Claude: Invece di fare copia-incolla manuale, esistono strumenti come ClaudeSync che automatizzano il passaggio di file a Claude. ClaudeSync è un tool open-source che sincronizza i file locali con i file di un Project su Claude.ai, in modo rapido e con filtri intelligenti
reddit.com
. Puoi scegliere quali cartelle o estensioni sincronizzare, e lui terrà aggiornato il Project (uploadando modifiche in tempo reale). Questo permette di avere su Claude sempre la versione corrente dei file chiave, senza doverli incollare ogni volta. Essendo open-source, è sicuro e personalizzabile
reddit.com
. Un flusso possibile: modifichi codice in VS Code, lanci claudesync push e poi chiedi a Claude (nel Project) di analizzare o modificare quei file sincronizzati.
Usare un IDE/chat integrata che legge il progetto: Un’alternativa è impiegare editor o estensioni che indicizzano l’intero codebase. Ad esempio, Cursor è un editor AI (derivato da VS Code) che indicizza automaticamente il progetto, permettendo all’AI di conoscere le relazioni tra file
jasonroell.com
. Quando scrivi o chiedi modifiche, Cursor ha già in contesto l’intero repository indicizzato e aggiornato in tempo reale, il che aiuta l’AI a tenere conto di tutti i file coinvolti. In altre parole, Cursor fornisce al modello una panoramica globale del codice, utile se lavori su un’app Next.js con molte parti collegate (componenti, API, modelli, etc.)
jasonroell.com
. Attenzione però: funzionalità avanzate come l’editing multi-file automatico potrebbero richiedere una sottoscrizione premium su Cursor
jasonroell.com
. Se non vuoi passare interamente a Cursor, sappi che esistono anche estensioni per VS Code che offrono funzionalità simili (ad esempio Sourcegraph Cody per la ricerca semantica nei repo, o Github Copilot Chat nella versione enterprise con visibilità dell’intero repo). Tuttavia, molte di queste soluzioni avanzate possono richiedere account a pagamento o configurazioni non banali.
Organizzazione modulare del codice: Una strategia “non tecnica” ma molto efficace è organizzare il progetto in modo modulare per funzionalità. Ad esempio, potresti strutturare Wolfinder in sottocartelle per feature (es: features/profili, features/matching, ecc.) contenenti ciascuna i file di model, API, componenti relativi a quella feature. Questo non solo è una buona pratica generale, ma facilita la vita all’IA: se le parti correlate sono raggruppate, ti basta fornire all’AI l’intera cartella della feature quando hai bisogno di assistenza su quella, senza includere codice non pertinente
reddit.com
. Inoltre, codice comune dovrebbe stare in utilità o librerie condivise; anche questo aiuta perché riduce duplicazioni e isola i contesti. Un utente riferisce che con LLM questa modularità è ancora più importante del solito, perché consente di controllare meglio l’ampiezza del contesto passato al modello
reddit.com
. Quindi valuta se rifattorizzare leggermente la struttura di Wolfinder in ottica feature modules (se già non lo è con il pattern di Next.js 14).
2. Tecniche di Context Management avanzate (LangChain, RAG, ecc.):
Per progetti davvero enormi o per evitare di dipendere solo sulla finestra di contesto, esistono approcci come il Retrieval-Augmented Generation (RAG). L’idea è: invece di caricare (o incollare) manualmente file di codice nell’input di ChatGPT/Claude, si costruisce un sistema che indicizza tutti i file (ad es. salvandone gli embedding in un vettore) e all’occorrenza recupera solo i pezzi rilevanti per la tua domanda, inserendoli dinamicamente nel prompt. In combinazione con la grande finestra di Claude, questo dà il meglio di entrambi i mondi
blog.lancedb.com
: puoi avere un intero codebase indicizzato e chiedere qualsiasi cosa, il sistema prenderà i frammenti pertinenti (con similarità semantica) e li passerà a Claude, sfruttando poi la sua capacità di leggere fino a 100k token di contesto
blog.lancedb.com
. Implementare RAG manualmente richiede competenze (utilizzo di strumenti tipo LangChain, un vettore store come LanceDB, FAISS o Pinecone, e scrivere un chatbot su misura). Per un singolo sviluppatore non esperto potrebbe essere eccessivo; tuttavia sappi che alcuni strumenti integrano già questa logica:
Sourcegraph Cody (menzionato prima) indicizza il tuo repository e ti permette di porre domande in linguaggio naturale: sotto il cofano usa embedding per cercare nei file e fornisce le risposte rilevanti.
OpenAI Plugins: se avessi accesso ai plugin di ChatGPT, ce ne sono alcuni per navigare documenti o codice, ma attualmente supporto per interi repo è limitato.
Soluzioni custom leggere: es. utilizzare la funzione di ricerca di VS Code combinata con l’AI. Puoi cercare dove appare una certa funzione o nome nel progetto usando grep o la ricerca IDE, e poi copiare quei snippet in chat. Non è automatico come RAG, ma svolge una forma di “retrieval manuale” mirato.
In sintesi, per gestire molti file usa strategie di selezione: dai in pasto all’IA solo ciò che serve quando serve, aiutandoti con script o tool di automazione. Mantieni il progetto organizzato e dotati, se possibile, di strumenti che ti evitino noiosi copia-incolla (Claude Projects, ClaudeSync, estensioni AI per IDE). Per utenti non tecnici, l’ideale è affidarsi a strumenti già pronti come un editor AI (Cursor) o un’estensione (Cody, Copilot Chat) piuttosto che implementare da zero soluzioni con LangChain, a meno che tu non sia curioso di sperimentare.
Integrazione sinergica di Claude, ChatGPT e altri strumenti
Usare più assistenti AI insieme può sembrare ridondante, ma in realtà ciascun tool ha punti di forza diversi. Ecco come un singolo sviluppatore può farli lavorare in sinergia durante lo sviluppo di Wolfinder:
GitHub Copilot (nel tuo IDE VS Code): Copilot è eccellente per il supporto in tempo reale mentre scrivi codice. Si integra nell’editor e fornisce suggerimenti automatici basati sul contesto immediato del file su cui stai lavorando
dev.to
. Ad esempio, iniziando a scrivere una funzione Next.js per un API route, Copilot potrebbe completarti automaticamente il codice HTTP di risposta, oppure mentre definisci uno schema Mongoose ti propone i campi in base al modello di dati. Questo ti fa risparmiare tempo su snippet ripetitivi e boilerplate. Copilot è ideale per velocizzare le micro-attività: scrivere una funzione, generare una configurazione, trasformare una descrizione in pseudo-codice in implementazione. Limiti: Copilot lavora principalmente sul file corrente e contesto locale; non ha visione globale di tutto il progetto (a parte magari qualche file aperto). Inoltre a volte suggerisce soluzioni non ottimali o basate su training datato. Va usato come autocomplete avanzato, sempre con giudizio umano. È “sempre acceso” e ti accompagna momento per momento.
ChatGPT (GPT-4) attraverso l’interfaccia Chat o plugin VS Code: ChatGPT è molto utile per Q&A, spiegazioni e generazione di blocchi di codice su richiesta. Rispetto a Copilot, è più adatto quando formuli una domanda esplicita o vuoi discutere un approccio. Ad esempio: “Come implemento l’autenticazione JWT in Next.js 14?”, oppure “Puoi spiegarmi il significato di questo errore e come risolverlo?”. ChatGPT eccelle nel fornire risposte dettagliate, passo-passo, e nel brainstorming iniziale. Puoi usarlo parallelamente a Copilot: mentre codifichi, se incontri un ostacolo, vai su ChatGPT (nel browser o in un’estensione di VS Code come CodeGPT o GitHub Copilot Chat) e poni la domanda. Se hai una porzione di codice che non funziona, incollala e chiedi debug o migliorie: ChatGPT può individuare bug o edge case. Vantaggi: conoscenza generale ampia, spiegazioni verbose, creatività. Svantaggi: contesto limitato (se la conversazione diventa lunga, potrebbe “dimenticare” i primi messaggi o dettagli), e come detto potrebbe non conoscere le ultimissime API di Next.js 14 a meno che siano state incluse nel suo training. In effetti, uno sviluppatore nota che ChatGPT/Claude a volte danno risposte su Next.js non aggiornate (es. citano metodi del Pages Router invece che le nuove Route Handler dell’App Router)
medium.com
. Per mitigare questo, fornisci tu a ChatGPT eventuali riferimenti aggiornati (documentazione Next.js) se sospetti che stia andando fuori strada, oppure utilizza Claude che ha addestramento più recente (Claude 2 conosce info almeno fino al 2023).
Claude AI (nell’interfaccia web o via API): Claude brilla quando hai bisogno di gestire molti dati insieme o ragionamenti complessi. Nel nostro scenario, userai Claude soprattutto per: 1) Domande o task che richiedono molto contesto, come analizzare l’architettura di più file, fare code review di un intero modulo, o applicare modifiche coordinate in più punti del codice; 2) Brainstorming e pianificazione ad ampio raggio, sfruttando la sua memoria di progetto (Project files) e la capacità di seguire conversazioni lunghe. Ad esempio, potresti discutere con Claude la struttura del database e dei modelli, fornendogli 4-5 file schema simultaneamente, cosa che GPT-4 standard non reggerebbe in input. Oppure puoi fargli leggere l’intero file di log di un errore complesso per farti aiutare nel debug. Claude tende ad essere meno guidato al codice specifico rispetto a Copilot, ma più “ragionatore”. Con il modello Claude 2 (o Claude Instant per risposte rapide), ottieni spesso suggerimenti molto dettagliati e attenti alla coerenza globale. Utilizzo tipico in sinergia: magari prima scrivi uno snippet con Copilot, poi chiedi a Claude di verificarlo nel contesto più ampio (passandogli il file intero e altri collegati). Oppure fai progettare un’intera componente a Claude, poi mentre la implementi concretamente accetti i suggerimenti di Copilot sulle singole righe.
Claude-Dev (Cline) – plugin/estensione VS Code: Vale la pena citare questo strumento open-source che incarna la massima integrazione tra Claude e l’ambiente di sviluppo. Claude-Dev (ribattezzato Cline) è un’estensione che porta Claude direttamente nel tuo editor/terminal. Ha capacità “agenti” avanzate: può leggere i log del terminale, capire errori di compilazione, ed eseguire comandi shell per conto tuo
jasonroell.com
. Immagina di scrivere npm run build e ottenere errori – Claude-Dev può analizzare l’output, aprire i file coinvolti, diagnosticare il problema e perfino provare ad applicare fix automaticamente
jasonroell.com
. Può anche effettuare modifiche su più file (anche se su progetti grandi riscrive interi file e può essere un po’ lento)
jasonroell.com
. Questo approccio è quasi come avere un “copilota” interattivo che non solo suggerisce ma agisce sull’ambiente (ovviamente chiede conferma prima di cambiare codice critico). Se sei un utente non esperto, inizialmente potresti trovare Cline complesso da usare (ha una sua sintassi di comandi, es. premendo # in VS Code per impartire istruzioni globali). Però una volta configurato, potrebbe aiutarti a automatizzare debug e refactoring su larga scala. Non è obbligatorio utilizzarlo, ma sappi che sviluppatori reali stanno sperimentando questi agenti IA per velocizzare enormemente il workflow.
Editor AI dedicati (es. Cursor): In alternativa a VS Code puro, editor come Cursor (o anche Replit Ghostwriter IDE) integrano profondamente l’AI. Cursor, come detto, offre completamento molto veloce (più reattivo di Copilot secondo alcuni) e conoscenza globale del progetto
jasonroell.com
jasonroell.com
. Puoi chiedere all’editor cose tipo “estrai questa funzione in un file util.js” e lui esegue l’operazione su più file. Nel tuo caso, potresti valutare di usare Cursor AI per implementare parti di Wolfinder, inserendo il tuo API key di Claude per sfruttarne il modello al meglio. La sinergia qui è tra un’interfaccia famigliare (simile VS Code) e la potenza del modello dietro. Se però sei già comodo con VS Code, potresti invece installare estensioni ChatGPT/Claude lì (ce ne sono varie: ad es. VS Code ChatGPT Extension di Gencay, DevGPT, oppure l’integrazione OpenAI via CodeTour, ecc.) per avere una chat AI a fianco dell’editor senza cambiare IDE.
Riepilogando la sinergia: Sfrutta Copilot per scrivere codice più velocemente e completare automaticamente parti ovvie. Sfrutta ChatGPT per rispondere a domande, ottenere spiegazioni o prototipi di codice quando non sei sicuro di come procedere. Sfrutta Claude quando hai bisogno di visione d’insieme, di elaborare molto contesto (ad es. revisione di più file) o di mantenere memoria di decisioni nel tempo. E usa gli strumenti integrativi (plugin VSCode, editor AI, ecc.) per colmare il gap tra questi assistenti e il tuo ambiente di sviluppo, così da non perdere tempo in copia-e-incolla e passaggi manuali. Un punto chiave è che nessuno di questi strumenti sostituisce il tuo giudizio: usali come amplificatori. Ad esempio, potresti far generare a ChatGPT una funzione e poi chiedere a Claude “questo codice ti sembra seguire le convenzioni del progetto?” (avendo caricato le convenzioni nei suoi Project files), e infine fare refactoring con l’IDE. Questa collaborazione multi-IA riduce gli errori e unisce i vantaggi di ciascun modello.
Strumenti e tecniche specifiche consigliate
Di seguito elenchiamo alcuni strumenti specifici (e loro plugin/estensioni) che un singolo sviluppatore su PC può adottare subito per implementare la strategia sopra descritta. Tutte queste soluzioni sono utilizzate concretamente da sviluppatori nelle loro attività quotidiane:
Claude.ai (Projects) – Assistente AI di Anthropic: l’uso di Claude attraverso l’interfaccia web con un Project dedicato è fondamentale per avere il contesto persistente e finestra 200k token. Assicurati di avere accesso a Claude 2 con Projects (richiede account Pro a pagamento)
beginswithai.com
. Crea un progetto “Wolfinder” e carica i file di documentazione/contesto come detto. Durante lo sviluppo, usa Claude via web per i compiti di alta visione: discussioni di design, review di codice multi-file, generazione di documenti di specifiche, debugging di log estesi. Plugin Claude per VSCode: se preferisci non passare dal browser, puoi provare l’estensione open-source Claude-Dev (Cline) menzionata, che collega Claude direttamente al tuo editor, permettendo comandi nel terminale e modifiche al codice. Questo richiede di configurare un API key Anthropic. In alternativa, uno strumento leggero è ClaudeSync: lo installi (pip install claudesync) e con pochi comandi (claudesync auth, claudesync project create, claudesync push) colleghi una cartella locale al Project su Claude
github.com
. Così puoi gestire il Project (upload, update file) dal terminale.
ChatGPT (GPT-4) e plugin – Assistente AI di OpenAI: usa ChatGPT nella sua interfaccia web per domande e richieste veloci. Puoi tenere una finestra del browser aperta con la chat GPT-4 relativa al progetto (magari una per Wolfinder back-end e una per front-end, se preferisci separare i contesti). Sfrutta la capacità di ChatGPT di spiegare concetti e proporre soluzioni alternative. Se hai ChatGPT Plus, abilita le Custom Instructions e scrivi una breve descrizione del tuo scenario (es. “Sto sviluppando un’app Next.js 14 + MongoDB chiamata Wolfinder, etc…”) nelle istruzioni permanenti: non è come avere 100k token di contesto, ma aiuta il modello a ricordare di cosa parli. Inoltre, esplora le estensioni VS Code per ChatGPT: ce ne sono molte gratuite. Ad esempio, ChatGPT - Genie AI o CodeGPT ti permettono di selezionare del codice nel tuo editor e mandarlo direttamente a ChatGPT con una domanda, vedendo la risposta accanto. GitHub ha rilasciato Copilot Chat (in beta) che fornisce una chat ancorata al tuo codice: se hai accesso, provalo, perché può riferirsi a rami del repository e fare domande sul progetto, sebbene per ora con limitazioni. In generale, avere ChatGPT a portata di click dentro l’IDE evita di dover continuamente passare al browser, migliorando il flusso.
GitHub Copilot – Autocompletamento avanzato: se non l’hai già, attiva Copilot nel tuo VS Code. Nel caso, sfrutta l’offerta gratuita per studenti o sviluppatori singoli se disponibile, altrimenti valuta l’abbonamento (vale l’investimento per la produttività). Oltre al completamento inline, verifica se hai accesso a Copilot Chat (richiede Copilot for Business o abilitazioni particolari): è una finestra di chat integrata in VS Code dove puoi fare domande sul codice, simile a ChatGPT ma con maggiore contesto dei file aperti. Copilot Chat può spiegarti una funzione o generare test unitari su richiesta. Anche senza la versione chat, Copilot normale consente già un uso sinergico: ad esempio scrivi un commento // funzione per validare la foto del profilo e attendi che Copilot suggerisca il codice intero. Spesso “dialogare” tramite i commenti nel codice può indirizzare Copilot a fornirti ciò che vuoi.
Cursor AI (editor alternativo) – IDE con AI integrata: se sei disposto a provare un nuovo ambiente di sviluppo, Cursor (cursor.dev) è un fork di VS Code potenziato dall’IA. Si porta dietro tutte le tue impostazioni ed estensioni VSCode, quindi la transizione è facile
jasonroell.com
. Ha completamenti molto reattivi e una finestra di chat integrata; soprattutto indicizza l’intero progetto per darti consapevolezza multi-file nell’IA
jasonroell.com
. Puoi connettere Cursor alle API di Claude (o OpenAI) inserendo la tua API key, così da usare Claude 100k token direttamente nell’editor. Questo setup potrebbe fornirti il meglio di Claude e Copilot insieme: velocità e conoscenza globale del codice. Nota: alcune funzionalità avanzate (tipo edit multi-file in un solo prompt) potrebbero essere a pagamento
jasonroell.com
. Puoi comunque usare la versione free per la maggior parte delle cose e valutare se vale passare alla pro. Cursor è usato da alcuni dev come rimpiazzo completo di VSCode + Copilot, quindi potrebbe essere una soluzione unica anziché gestire troppi tool separati.
Aider (AI CLI avanzata) – AI pair programmer via terminale: Aider è un tool open-source che ti permette di chattare con un LLM per modificare il tuo codice locale, integrandosi con Git. Lo installi con pip e lo esegui da terminale indicando quali file vuoi coinvolgere. La cosa potente è che Aider crea una mappa interna del tuo codebase (usa embedding) che gli consente di scalare a progetti grandi e capire dove fare modifiche
aider.chat
. Può collegarsi a modelli OpenAI o Anthropic (Claude) se fornisci le API key, e supporta anche modelli locali. Ad esempio, puoi dire: “Aggiungi un campo age al modello User e propaga i cambiamenti in tutte le API e validazioni” – Aider cercherà nei file dove serve aggiungere quel campo e proporrà le modifiche, facendoti poi vedere il diff. Ha integrazione con Git: ogni cambiamento viene committato separatamente con messaggi sensati, così hai una traccia chiara di cosa l’AI ha fatto
aider.chat
. In più, puoi richiamarlo dall’editor con un commento speciale e lui agirà (c’è integrazione ad es. con vim/emacs, e dovrebbe funzionare anche con VSCode terminal). Per un non esperto, Aider potrebbe far paura inizialmente, ma ha un’ottima documentazione e community. Può essere un modo di applicare le modifiche suggerite dall’AI direttamente nel tuo codice in locale, in maniera controllata (grazie ai commit puoi sempre tornare indietro). In pratica è come avere Claude/GPT nel terminale che edita il codice seguendo le tue indicazioni in linguaggio naturale.
Altre estensioni utili:
ESLint/Prettier + AI fix: Mantieni attivi i linters e formatter. Alcuni plugin AI come Amazon CodeWhisperer o lo stesso Copilot possono aiutare a correggere errori segnalati da ESLint. Anche Claude-Dev, come detto, può leggere i warning e risolverli.
Testing assistito: Puoi usare ChatGPT/Claude per scrivere test unitari o di integrazione per il tuo Next.js. Ad esempio, con Jest puoi chiedere “scrivi test per la funzione X dato questo file”. Questo non solo ti dà test (che aiutano a garantire che l’app funzioni), ma spesso evidenzia comportamenti non considerati. Strumenti come Aider possono poi inserire questi test nel progetto automaticamente.
Documentazione e commenti: Usa l’AI per generare documentazione del codice. Puoi selezionare una funzione e chiedere a ChatGPT “documenta questa funzione con JSDoc”. Oppure chiedi a Claude di riassumere cosa fa un file e aggiungi quel riassunto come commento all’inizio. Questo ti sarà utile anche mesi dopo, e intanto coinvolge poco sforzo perché lo fa l’AI.
LangChain/automazioni specifiche: Se volessi proprio sperimentare, potresti creare piccoli script Python che interrogano l’API di Claude o GPT per compiti batch. Ad esempio, un tool che ogni sera legge il tuo repository e genera un breve rapporto (changelog) in linguaggio naturale su cosa è cambiato, o che monitora i TODO nel codice e chiede a GPT di proporre soluzioni. Queste sono idee avanzate e opzionali – la strategia non ne dipende – ma mostrano che le possibilità di automazione con AI sono infinite. Molti sviluppatori reali creano workflow personalizzati (usando GitHub Actions, script Node, ecc.) in cui integrano chiamate AI per automatizzare parti del ciclo di sviluppo.
Tutti i suddetti strumenti funzionano in locale sul tuo computer (o necessitano solo di API key per chiamare servizi cloud), quindi come singolo developer sullo stesso PC puoi configurarli una tantum e averli sempre disponibili. Sfrutta il fatto di lavorare sempre sulla stessa macchina: ad esempio, mantieni le sessioni loggate (VS Code con estensioni configurate, browser con cookie per ChatGPT e Claude attivi) così non devi rifare login o reimpostare nulla ogni volta. Puoi anche scrivere qualche script di avvio che apra l’ambiente di lavoro: ad esempio lancia VS Code, apre il browser con le schede di Claude e ChatGPT, avvia magari claudesync in background. In questo modo, con un doppio click sei subito pronto a lavorare col supporto di tutta la tua “squadra” AI.
Esempi di flussi di lavoro assistiti dall’AI
Per rendere più concreti questi concetti, vediamo due scenari pratici nello sviluppo di Wolfinder e come utilizzare in sinergia Claude, ChatGPT e gli altri strumenti per massimizzare l’efficienza.
Esempio 1: Implementazione di una nuova funzionalità
Scenario: Supponiamo di voler aggiungere a Wolfinder la funzionalità “Mi Piace” sui profili (un utente può mettere like a un altro profilo). Questo richiede cambiamenti sia nel front-end (bottone e chiamata API), sia nel back-end (API route per registrare il like, modello Mongoose per salvarlo, eventualmente notifica). Flusso di lavoro ottimizzato:
Brainstorming e progettazione con Claude: Prima di scrivere codice, apri Claude (Project Wolfinder) e descrivi la funzionalità che vuoi aggiungere. Ad esempio: “Vorrei aggiungere la feature per cui un utente può mettere 'like' al profilo di un altro. Come potrei strutturarla? Ecco il modello User attuale e la struttura delle API.” (Allega magari il file UserModel.js e menziona l’API esistente per il matchmaking se c’è qualcosa di simile). Grazie al contesto del progetto, Claude conoscerà già l’architettura generale. Potrebbe suggerirti di creare un nuovo schema Like oppure di aggiungere un campo array nel modello utente, e di esporre un endpoint POST /api/like con determinati parametri. Discuti con Claude i pro e contro (ad esempio, preferiamo non creare troppa annidazione nel documento utente? come gestiremo la reciprocità del match?). Annota le decisioni finali – puoi chiedere a Claude alla fine: “Ricapitolami il piano per implementare i like”. Questo output (che potrebbe includere: “1. Aggiungere campo likes al modello User… 2. Creare API route … 3. Aggiornare frontend…”) salvalo nel Project o nel tuo file di note.
Generazione boilerplate con ChatGPT: Ora che hai un piano, puoi passare a scrivere il codice. Inizia dal back-end: apri VS Code e crea il file per la nuova API route, es. pages/api/like.js (o nell’app router Next 14, magari app/api/like/route.js). Invece di partire da zero, copia nel prompt di ChatGPT la struttura di un’API route esistente (per mantenere lo stile) e poi chiedi: “Scrivi un handler Next.js per l’endpoint POST /api/like che prende in body un targetUserId e registra un like dall’utente loggato (ID nel token JWT) verso quell’utente. Usa Mongoose.”. ChatGPT fornirà un esempio di codice per quell’endpoint, completo di verifica auth, aggiornamento DB e risposta. Probabilmente menzionerà funzioni utili (ad es. controllare se già esiste un like, o se c’è un match reciproco). Copia quel codice in VS Code. Fai lo stesso per il modello se serve: ad esempio, chiedi a ChatGPT come modificare UserModel per tracciare i likes. In parallelo, per il front-end, puoi chiedere: “Come implementare il bottone Like in React/Next.js? Mi daresti un esempio di componente che chiama l’API?”. Otterrai un componente React con un bottone che al click fa fetch POST su /api/like e gestisce la risposta (magari disabilitando il bottone dopo il click). Copia/incolla anche questo. Nota: Questi codici generati sono un ottimo punto di partenza ma vanno integrati nel tuo progetto (ad esempio, ChatGPT non conosce esattamente la struttura dei tuoi componenti, quindi dovrai adattarlo al file giusto, importare i contesti autentificazione, ecc.).
Utilizzo di Copilot mentre scrivi: Mentre inserisci il codice suggerito da ChatGPT nei tuoi file, GitHub Copilot entrerà in gioco proponendo completamenti o aggiustamenti. Ad esempio, dopo aver incollato l’handler API, potresti iniziare a scrivere la logica di verifica se l’utente target esiste; Copilot potrebbe suggerirti direttamente la query Mongoose User.findById(targetUserId). Accetta i suggerimenti se pertinenti. In pratica, Copilot ti aiuta a riempire i dettagli mancanti e ad adattare lo snippet generico al tuo contesto specifico (ad esempio, nomi di variabili, funzioni utilità che hai nel progetto, ecc.).
Verifica multi-file con Claude: A questo punto hai modificato vari punti: modello, API, componente front-end. È utile far rivedere a Claude l’insieme per assicurarti che tutto sia coerente. Puoi usare Claude in diversi modi qui: se hai ClaudeSync, assicura che i file aggiornati siano sincronizzati, poi nel chat di Claude chiedi “Puoi verificare se la feature Like è implementata correttamente? Ecco i file coinvolti:” e incolli la versione finale di ciascun file (o usi lo script di concatenazione per unire 2-3 file). Grazie alla sua ampia memoria, Claude leggerà tutti i file insieme e potrebbe individuare problemi (es. “attenzione, nel modello User aggiungi un campo likes ma nell’API usi un altro nome” o “manca la gestione del caso di like duplicato”). Se trova errori o edge cases, segnalali e suggerisci correzioni. Puoi quindi applicare queste correzioni. Questo passaggio è cruciale perché un singolo ChatGPT focusing su un file potrebbe aver perso la visione d’insieme (ad esempio dimenticare di aggiornare qualcosa nel frontend).
Test e debug con l’aiuto dell’AI: Ora prova la funzionalità manualmente o con test automatici. Se qualcosa non funziona (supponiamo che cliccando il bottone ottieni un errore 500), copia l’errore dal terminale o dal log e chiedi a ChatGPT di aiutarti: “Sto ottenendo questo errore quando chiamo l’API like: [stacktrace]. Cosa potrebbe essere?”. Spesso l’errore potrebbe essere banalmente uno undefined perché ti sei dimenticato di passare il JWT token nel fetch; ChatGPT te lo farà notare. In caso di bug più subdoli, Claude può tornare utile: puoi fornirgli l’intero log o persino condividere l’intero file di codice con l’errore evidenziato e chiedere una diagnosi approfondita. Claude con il contesto del progetto potrebbe capire se c’è un problema di logica (es. “stai aggiungendo l’ID due volte nell’array, causando un errore di schema” ecc.).
Rifinitura e documentazione: Una volta che la feature funziona, puoi chiedere a ChatGPT di generare qualche test unitario per la nuova API di like. Implementa i test suggeriti e falli girare (magari usando un plugin VSCode tipo Jest Runner). Se i test passano, sei a buon punto. Infine, fai documentare la nuova feature: chiedi a Claude di aggiornare il file di descrizione del progetto nel Project (o fallo tu manualmente) per includere come funziona la feature Like. Questo aggiorna il contesto per future sessioni. Puoi anche far generare a ChatGPT un breve changelog o un messaggio di commit descrittivo che riassuma tutto ciò che hai fatto (utile se usi Git).
In questo flusso, notiamo come Claude ha aiutato nel disegno generale e verifica cross-file, ChatGPT ha generato rapidamente codice e spiegazioni per implementare le parti, e Copilot ha colmato i dettagli durante la digitazione, il tutto orchestrato dal programmatore che prende le decisioni finali.
Esempio 2: Refactoring e risoluzione di bug complessi
Scenario: Immagina di dover fare un refactoring importante in Wolfinder, ad esempio cambiare il modo in cui vengono caricati i profili nei risultati (passare da una certa query MongoDB a un’altra più efficiente), oppure di voler ristrutturare il codice spostando delle funzionalità in un modulo separato. Alternativamente, considera un bug difficile: ad esempio, ogni tanto il server cade per un errore di serializzazione di un oggetto circolare che non capisci da dove proviene. Flusso di lavoro ottimizzato:
Analisi iniziale con Claude (contesto ampio): Per un refactoring ampio, inizia descrivendo cosa vuoi cambiare e perché a Claude. Ad esempio: “Vorrei ottimizzare la funzione di ricerca profili perché attualmente fa due query separate su Mongo e poi un merge in memoria, causando lentezza. Ti mostro il codice attuale (file SearchService.js) e il modello utente; puoi aiutarmi a pianificare un refactoring?”. Fornisci i file pertinenti. Claude, ragionando sul contesto, potrà proporre una strategia (es. “puoi utilizzare un’unica aggregazione MongoDB con lookup, ecco come…” oppure “scomponiamo la logica in due funzioni…”). Chiedi a Claude di creare un piano a fasi: p.es. Fase1: scrivere nuovi metodi, Fase2: aggiornare API a usarli, Fase3: rimuovere vecchio codice una volta testato
reddit.com
. Salva questo piano nel Project o come nota.
Per un bug complesso, prepara il terreno raccogliendo più informazioni possibili: log di errore, passi per riprodurlo, ipotesi. Poi presenta tutto a Claude: “Sto riscontrando un errore intermittente: [messaggio di errore]. Questo succede quando faccio X. Ecco i file che credo coinvolti: [API file, model, maybe utility]. Puoi aiutarmi a trovare la causa?”. La grande memoria di Claude consente di ingurgitare magari centinaia di righe di log e codice insieme, cosa che manualmente è arduo analizzare. Claude potrebbe individuare che l’errore di serializzazione deriva da un oggetto Mongoose non plain che stai cercando di passare a res.json(), suggerendoti di convertirlo con .toObject() prima di serializzare, ad esempio.
Esecuzione guidata con strumenti appropriati:
Nel caso del refactoring, una volta definito il piano, puoi utilizzare uno strumento come Aider per implementarlo gradualmente. Ad esempio, dici ad Aider (che usa GPT/Claude dietro le quinte): “Apri SearchService.js e implementa una funzione searchProfilesOptimized() che faccia la stessa cosa di searchProfilesLegacy() ma in modo più efficiente usando un’aggregazione MongoDB”. Aider cercherà nel file e creerà la funzione secondo le istruzioni. Poi gli dici: “Modifica l’endpoint /api/search per usare searchProfilesOptimized invece di searchProfilesLegacy” – lui farà il cambiamento e magari committerà il vecchio codice marcandolo come deprecato. Questo è un esempio di refactoring assistito dove tu scrivi comandi in linguaggio naturale e l’AI applica i cambiamenti su più file. Se non ti fidi a far fare tutto a uno strumento, puoi comunque fare tu i passi e usare ChatGPT/Copilot in maniera tradizionale. Una via di mezzo potrebbe essere usare Claude in modalità interattiva: incolli la funzione vecchia e chiedi “riscrivila in modo più efficiente”, poi la inserisci tu; incolli l’API e chiedi “aggiornala”, ecc., un file alla volta.
Nel caso del bug, supponiamo che Claude abbia indicato la probabile causa. Procedi a correggerla: ad esempio, aggiungi .toObject() dove serve. Puoi usare Copilot per suggerire dove aggiungerlo in tutto il file (spesso, se scrivi .toO Copilot completerà con .toObject() in tutti i punti giusti). Dopodiché, scrivi un test (o uno script) per verificare che il bug sia risolto. Anche qui ChatGPT può aiutare: “Mi scrivi un test Jest che verifica che chiamando l’API X non lanci più l’errore Y?”. Esegui il test e assicurati che passi.
Verifica e completamento del refactoring: Dopo aver fatto cambi consistenti, rivedi tutto con Claude. Forniscigli i file modificati e anche quelli adiacenti per sicurezza. Chiedi: “Vedi problemi o qualcosa che ho dimenticato dopo questo refactoring?”. Magari noterà che non hai aggiornato i test o che c’è un commento/documentazione obsoleto che ancora parla della vecchia funzione. Sistema questi dettagli. Se il refactoring coinvolge molte parti, potresti chiedere a Claude di generare un breve documento di migrazione: ad esempio, “Puoi riassumermi le differenze tra la vecchia implementazione e la nuova, così da comunicarle al team (o al me stesso futuro)?”. Questi documenti li metti nei Project files come riferimento storico.
Risoluzione di bug regressioni: Un refactoring può introdurre bug inattesi. Se saltano fuori, siamo di nuovo nella fase di debug: usa ChatGPT per errori puntuali e Claude per analisi più ampie. Ad esempio, se dopo il refactoring la ricerca non ritorna più certi risultati, potresti chiedere a ChatGPT: “Prima questo input produceva 5 risultati, ora 3, quali casi sto perdendo?”. A volte persino far confrontare a ChatGPT o Claude il vecchio codice vs nuovo codice può evidenziare parti rimosse accidentalmente. Incolla entrambi e chiedi un confronto: l’AI potrebbe dire “nel nuovo codice non filtri per status attivo dell’utente, che invece il vecchio faceva – questo spiega la differenza”.
Consolidamento: Dopo che tutto funziona, aggiorna la documentazione del progetto (Claude Project o README). Inoltre, fai clean-up finale: Copilot può aiutare a rimuovere eventuali residui (se scrivi “rimuovi funzione legacy” magari ti segnala come completamento dove sta e la elimina). Esegui tutti i test per essere sicuro che niente sia rotto. A questo punto, puoi avere la soddisfazione di chiedere a Claude: “Genera un changelog per la versione X.Y: abbiamo migliorato la ricerca profili, fixato bug serializzazione, ecc.” e magari incollarlo nelle note di release.
Questi esempi mostrano come alternare fasi di progettazione/verifica (Claude) con fasi di implementazione assistita (ChatGPT/Copilot/Aider) rende il processo di sviluppo fluido e continuo. Anche quando il contesto supera le capacità di una singola chat (es. un bug con tanti file coinvolti), l’uso combinato di strumenti e la suddivisione del lavoro in task mirati consente di non perdersi.
Best practice per un singolo sviluppatore sempre sullo stesso computer
Infine, ricapitoliamo alcune best practice generali per massimizzare l’efficienza e la continuità del contesto lavorando da soli con l’AI:
Documenta e aggiorna continuamente il contesto: Fai dell’abitudine di scrivere o aggiornare un file di riassunto del progetto ogni volta che succede qualcosa di importante (nuove decisioni architetturali, nuovi endpoint, cambi di schema DB, ecc.). Questo file serve a te e all’AI: lo puoi caricare nei Project di Claude e all’occorrenza passarlo a ChatGPT. È come creare la “memoria” del progetto a cui attingere. Come suggerito nelle linee guida di Claude Code, considera di mantenere un file CLAUDE.md o simile, con dentro comandi comuni, convenzioni, e note importanti sul progetto
anthropic.com
anthropic.com
. Così Claude (o qualunque altra AI) potrà vedere quello per primo e capire il contesto (Claude Code per esempio include automaticamente CLAUDE.md nel prompt iniziale
anthropic.com
). Non dare per scontato che l’AI ricordi: meglio ridondare informazioni chiave (es. “stiamo usando Next.js 14 con App Router, no Pages”) nelle tue interazioni, oppure tenerle in istruzioni permanenti.
Lavora per feature/moduli isolati: Concentrati su un aspetto alla volta del progetto e coinvolgi l’AI su quello, reimpostando il contesto se necessario quando passi a un altro ambito. Questo ti aiuta a rimanere nei limiti di contesto e anche mentalmente organizzato. Ad esempio, se oggi lavori sul modulo di chat interna di Wolfinder, resta su quell’argomento nella chat, utilizza i file pertinenti, e non mischiare discorsi di altri moduli. Domani, se passi a qualcos’altro, puoi iniziare una nuova sessione (in Claude Project o un nuovo thread ChatGPT) focalizzata su quello – sapendo che le informazioni di background sono comunque a portata di mano se servono.
Sfrutta la velocità dell’AI ma verifica sempre: Il fatto che Claude o ChatGPT possano leggere/riscrivere centinaia di righe in pochi secondi è allettante, ma ricorda di rivedere attentamente ogni output prima di integrarlo. Controlla che il codice generato sia corretto e sicuro. Evita di fare blind copy-paste: meglio usare gli strumenti come Aider o il diff viewer di VS Code per capire esattamente cos’è cambiato. Esegui test frequenti. L’IA può introdurre bug sottili o logica errata; il tuo compito è essere il QA di te stesso e dell’AI.
Gestisci le credenziali e i dati sensibili con attenzione: Se il tuo progetto ha chiavi API, password, ecc., non inserirle mai nelle richieste all’AI (specialmente su servizi cloud di terzi). Usa placeholder. Ad esempio, invece di passare la vera stringa di connessione MongoDB a ChatGPT, sostituiscila con MONGODB_URL. Similmente, se hai dati utente reali nel DB, non fornirli in chiaro all’AI. Lavora con dati fittizi quando spieghi scenari (l’AI non ha bisogno dei dati reali per aiutarti).
Approfitta della community e delle risorse aggiornate: Gli strumenti AI evolvono rapidamente. Mantieniti aggiornato leggendo esperienze di altri sviluppatori (su blog, Reddit, Medium) – ad esempio la discussione su Reddit che citavamo ha dato spunti pratici su come usare i Projects di Claude al meglio
reddit.com
reddit.com
. Potresti scoprire nuovi plugin o workflow che semplificano ulteriormente il lavoro. Non esitare a cercare soluzioni specifiche, come “Claude ignora file project” o “ChatGPT context limit workaround” – spesso qualcuno ha già risolto quel problema.
Continuità oltre i limiti del contesto: se proprio ti trovi con informazioni che eccedono il contesto (ad es. un file enorme di codice), una tecnica low-tech è spezzare il problema: riassumi parti con l’AI e usa i riassunti per continuare. Ad esempio, se hai un file di 2000 righe, chiedi a Claude di riassumere ogni 500 righe, poi fornisci i riassunti combinati e chiedi un’azione. Questo è un approccio manuale a qualcosa che farebbe LangChain automaticamente, ma può funzionare in emergenza. Oppure fai analizzare all’AI solo una porzione alla volta, con domande specifiche, e assembla tu le risposte per avere la visione intera. In ultimo, se ti accorgi che stai lottando troppo col contesto, potrebbe essere segno di troppa complessità non necessaria: valuta se semplificare il design o la quantità di codice, il che porta beneficio sia a te che all’AI.
Con queste best practice, dovresti riuscire a mantenere un ritmo di sviluppo elevato e costante. L’AI diventa parte integrante del tuo ambiente di lavoro: come un collega a cui chiedi aiuto o un assistente instancabile che prepara bozze di codice e documentazione. Tu puoi focalizzarti sulle parti creative e sulle decisioni, delegando all’AI i compiti ripetitivi o di ricerca di soluzione. In conclusione, per completare Wolfinder in modo efficiente:
Progetta con l’AI, Codifica con l’AI, Verifica con l’AI, in un ciclo continuo fino a raggiungere il risultato desiderato.
Riduci il carico cognitivo tenendo sempre disponibile il contesto (Claude Projects, appunti) e lasciando che sia l’AI a ricordare dettagli e pattern al posto tuo.
Mantieni però il controllo: guida l’AI, scegliendo lo strumento giusto per ogni sottoproblema e valutandone criticamente gli output.
Seguendo questa strategia, anche uno sviluppatore singolo con esperienza limitata può affrontare con successo la realizzazione di una piattaforma full-stack complessa, tagliando tempi e difficoltà in modo drastico ma senza rinunciare alla qualità e alla coerenza del codice. Buon lavoro e buona programmazione assistita! Fonti e riferimenti:
Documentazione Anthropic Claude: Claude Projects e contesto persistente
beginswithai.com
beginswithai.com
Discussione Reddit su utilizzo di Claude con progetti di codice
reddit.com
reddit.com
reddit.com
Articolo Jason Roell – Esperienza con Cursor (VSCode AI) e Claude-Dev
jasonroell.com
jasonroell.com
Strumento open-source ClaudeSync per sincronizzare file con Claude
reddit.com
Strumento open-source Aider – pair programming da terminale (mappa l’intero codebase per LLM)
aider.chat
Medium Sangam Pandey – Attenzione alle risposte datate su Next.js da ChatGPT/Claude
medium.com
Blog LanceDB – Combinare contesto lungo di Claude con retrieval su vector DB (RAG)